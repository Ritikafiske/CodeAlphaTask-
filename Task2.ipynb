{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJX4GrXQj6KntyN3mEI7rb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ritikafiske/CodeAlphaTask-/blob/main/Task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S206i6GdvEge"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def extract_features(file_path):\n",
        "  data, sample_rate = librosa.load('/content/features.csv', duration=2.5, offset=0.5)\n",
        "  mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
        "  return mfccs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/features.csv')\n",
        "\n",
        "print(df.info())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpjVhLcYaVWg",
        "outputId": "968b50d8-772f-4e49-8c5d-96bab861ab95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4320 entries, 0 to 4319\n",
            "Data columns (total 21 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       4320 non-null   float64\n",
            " 1   1       4320 non-null   float64\n",
            " 2   2       4320 non-null   float64\n",
            " 3   3       4320 non-null   float64\n",
            " 4   4       4320 non-null   float64\n",
            " 5   5       4320 non-null   float64\n",
            " 6   6       4320 non-null   float64\n",
            " 7   7       4320 non-null   float64\n",
            " 8   8       4320 non-null   float64\n",
            " 9   9       4320 non-null   float64\n",
            " 10  10      4320 non-null   float64\n",
            " 11  11      4320 non-null   float64\n",
            " 12  12      4320 non-null   float64\n",
            " 13  13      4320 non-null   float64\n",
            " 14  14      4320 non-null   float64\n",
            " 15  15      4320 non-null   float64\n",
            " 16  16      4320 non-null   float64\n",
            " 17  17      4320 non-null   float64\n",
            " 18  18      4320 non-null   float64\n",
            " 19  19      4320 non-null   float64\n",
            " 20  labels  4320 non-null   object \n",
            "dtypes: float64(20), object(1)\n",
            "memory usage: 708.9+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d32d2e66",
        "outputId": "c048bcf2-70ff-4a41-f024-3334cad47043"
      },
      "source": [
        "print(df.columns)\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
            "       '13', '14', '15', '16', '17', '18', '19', 'labels'],\n",
            "      dtype='object')\n",
            "            0           1          2          3          4         5  \\\n",
            "0 -637.701233  104.299019   4.894947  20.494011  12.552954  2.851410   \n",
            "1 -596.908460   86.871936   9.470162  17.109819  11.198966  1.541056   \n",
            "2 -698.086548   99.795929   1.892679  19.915264   7.532868  1.265761   \n",
            "3 -279.141052   41.092949 -21.319229   7.802911 -13.140503 -9.407660   \n",
            "4 -160.074686   17.576058  -2.147436   3.133417  -4.745002 -6.510771   \n",
            "\n",
            "           6         7          8         9  ...         11        12  \\\n",
            "0  -6.633390 -4.091278 -10.423918 -6.406950  ...   0.172893 -1.170210   \n",
            "1  -6.677264 -5.755428  -9.684472 -6.891256  ...   0.033803 -1.986515   \n",
            "2  -9.188656 -5.798194 -12.299710 -4.976400  ...  -1.639542 -2.603761   \n",
            "3 -15.580647 -6.097223 -24.700903 -9.640293  ... -10.305976 -4.092835   \n",
            "4  -5.911591 -4.481506  -9.470598 -5.907823  ...  -4.088007 -1.817639   \n",
            "\n",
            "         13         14        15         16        17        18        19  \\\n",
            "0 -5.292450  -0.573319  1.019471  -3.492607 -3.468123 -1.214944  1.971239   \n",
            "1 -5.103855  -1.253110  0.514896  -3.268317 -4.502895  0.167153  0.256732   \n",
            "2 -4.890347  -0.879222 -1.250208  -3.449960 -4.708529 -0.086224 -3.034044   \n",
            "3 -5.817179 -10.731523 -0.823596 -15.885103 -2.014258 -6.173852 -5.331760   \n",
            "4 -2.994765  -4.893176 -2.880436  -7.163400 -2.147345 -2.359248 -3.746217   \n",
            "\n",
            "       labels  \n",
            "0   male_calm  \n",
            "1   male_calm  \n",
            "2   male_calm  \n",
            "3  male_angry  \n",
            "4  male_angry  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming df is already loaded from '/content/features.csv' in a previous cell\n",
        "# If df is not globally available, you might need to re-run the cell where df is defined.\n",
        "\n",
        "# Extract features (all columns except the 'labels' column)\n",
        "features = df.iloc[:, :-1].values\n",
        "\n",
        "# Extract labels (the 'labels' column)\n",
        "labels = df['labels'].values\n",
        "\n",
        "print(f\"Shape of features: {features.shape}\")\n",
        "print(f\"Shape of labels: {labels.shape}\")"
      ],
      "metadata": {
        "id": "20UjnjwrvZhY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ede410d-4c6d-40db-d671-d67ab25c1513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (4320, 20)\n",
            "Shape of labels: (4320,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UMvPrARhvFFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f952b27a"
      },
      "source": [
        "# Task\n",
        "Simplify the Keras model to a minimal architecture (input and output layers only) to isolate the cause of the `ValueError: None values not supported.` during `model.fit`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48edc75b"
      },
      "source": [
        "## debug_model_fit_error\n",
        "\n",
        "### Subtask:\n",
        "Simplify the Keras model to a minimal architecture (input and output layers only) to isolate the cause of the `ValueError: None values not supported.` during `model.fit`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "kBHBGe7MbKTG",
        "outputId": "5e7fdcca-b8ca-4145-e493-87f227eaf205"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Extract features (all columns except the 'labels' column)\n",
        "features = df.iloc[:, :-1].values\n",
        "\n",
        "# Extract labels (the 'labels' column)\n",
        "labels = df['labels'].values\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "labels_encoded = le.fit_transform(labels)\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(features,labels_encoded,test_size=0.2,random_state=42)\n",
        "\n",
        "# Explicitly cast data types to ensure compatibility with Keras\n",
        "x_train = x_train.astype(np.float32)\n",
        "x_test = x_test.astype(np.float32)\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "\n",
        "model = Sequential() # Create an empty Sequential model\n",
        "model.add(tf.keras.Input(shape=(features.shape[1],))) # Explicitly add the Input layer\n",
        "model.add(Dense(len(le.classes_), activation = 'softmax')) # Only the output layer\n",
        "\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train,epochs=50,batch_size=32) # Removed validation_data\n",
        "y_pred=model.predict(x_test)\n",
        "y_pred=np.argmax(y_pred,axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "None values not supported.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2211782215.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Removed validation_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optree/ops.py\u001b[0m in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0mleaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreespec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_is_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0mflat_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_up_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrests\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mflat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: None values not supported."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b123b263"
      },
      "source": [
        "# Task\n",
        "Convert `x_train` and `y_train` into a `tf.data.Dataset` and pass it to `model.fit`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f06d289f"
      },
      "source": [
        "## debug_model_fit_error\n",
        "\n",
        "### Subtask:\n",
        "Convert `x_train` and `y_train` into a `tf.data.Dataset` and pass it to `model.fit` to resolve the `ValueError: None values not supported.`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c407a27"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The `ValueError: None values not supported.` encountered during `model.fit` was successfully resolved by converting `x_train` and `y_train` into a `tf.data.Dataset` object.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   When encountering `ValueError: None values not supported.` errors with `model.fit` in TensorFlow, explicitly converting input data to `tf.data.Dataset` is an effective debugging strategy.\n"
      ]
    }
  ]
}